# How Far Scaling Laws Will Extend

[Source:](https://www.youtube.com/watch?v=aTQWymHp0n0)*Microsoft CTO Kevin Scott on How Far Scaling Laws Will Extend*

The current LLM era is the result of scaling the size of models in successive waves (and the compute to train them). It is also the result of better-than-Moore’s-Law price vs performance ratios in each new generation of Nvidia GPUs. The largest platform companies are continuing to invest in scaling as the prime driver of AI innovation.

Are they right, or will marginal returns level off soon, leaving hyperscalers with too much hardware and too few customer use cases? To find out, we talk to Microsoft CTO Kevin Scott who has led their AI strategy for the past seven years. Scott describes himself as a “short-term pessimist, long-term optimist” and he sees the scaling trend as durable for the industry and critical for the establishment of Microsoft’s AI platform.

Scott believes there will be a shift across the compute ecosystem from training to inference as the frontier models continue to improve, serving wider and more reliable use cases. He also discusses the coming business models for training data, and even what ad units might look like for autonomous agents.

|Section|Key Points|
|-|-|
|Evolution of AI and Future Prospects|Current AI models may seem expensive or fragile, but these issues will improve over time, making technology cheaper and more robust. As each generation of AI models scales, more complex and previously unimaginable tasks become possible.|
|Kevin Scott's Journey|Kevin grew up in rural Virginia and became fascinated with computers during the personal computing revolution. He majored in computer science and minored in English literature. He initially considered a PhD in literature but chose a pragmatic path in computer science due to financial constraints.His career includes significant roles at Google, AdMob, LinkedIn, and finally, Microsoft.|
|Role of PhDs in AI|While PhDs are valuable for complex AI platform components, they are not mandatory for all roles in AI. Practical AI applications in various fields can be developed without a PhD, focusing on collaboration and leveraging existing platforms.|
|Microsoft’s AI Strategy|Microsoft aims to build a comprehensive AI platform that includes everything from frontier models to developer tools. The company listens to developers and aims to fill in the gaps to make AI technology more accessible and robust.The strategy emphasizes making powerful AI accessible to a broader audience and scaling up investments in AI.|
|Challenges and Learnings|Microsoft initially missed some opportunities in AI by not focusing investments early enough. The realization of the importance of scale in AI came around 2017-2018, especially after Google's BERT paper highlighted significant advancements. Microsoft restructured and accelerated its AI efforts, leading to partnerships like the one with OpenAI.|
|AI Model Development and Scale|Large language models (LLMs) like GPT have shown that models can be applied to various tasks, moving from narrow to broader applications. OpenAI shared Microsoft’s belief in scaling and the emergence of platform characteristics in AI as models grew larger.|
|Economic Considerations in AI|While training AI models can be expensive, inference (the application of trained models) is expected to become a more significant cost driver. Advances in hardware (like Nvidia’s GPUs) and networking are making AI training more cost-effective, but inference requires different architectural considerations. Innovation in inference environments is likely to lead to more diversity and faster improvements compared to training environments.|
|Current Market Dynamics and Frontier Models||
|Demand-Supply Balance|There is ongoing discussion about the market demand for AI models. As platforms expand and become more capable, the demand for AI is expected to increase. However, the specific shape and nature of this demand are likely to evolve.|
|Resource Intensity|Building frontier models (cutting-edge AI models) is highly resource-intensive. While these models are becoming more accessible than in the past, there is a question of how many such models are actually needed, given their similar capabilities.|
|Specialization vs. Generalization|There's a debate about whether companies need to build their own frontier models or if they can rely on existing ones. Building a frontier model is likened to creating unique smartphone hardware and OS just to develop a mobile app—it's often unnecessary.|
|Data Quality and Training Models||
|Data Quality Over Quantity|The importance of high-quality data for training AI models is emphasized over sheer volume. This shift creates an economic framework for forming partnerships to access valuable training data.|
|Business Models for Data Access|As high-quality training data becomes scarcer, new business models are likely to emerge, such as licensing and subscription models. This parallels how search engines monetize access to indexed data.|
|Practical Applications and Challenges|
|AI as Assistive Technology|Microsoft's strategy with AI, particularly with their co-pilots, focuses on assisting rather than replacing human cognitive work. Successful examples like GitHub Copilot show practical, domain-specific AI applications.|
|General vs. Specific AI|More general AI co-pilots face challenges in taking precise autonomous actions, especially where the stakes are high. Domain-specific tools are currently more reliable and easier to implement effectively.|
|Technological Advancements and Scalability||
|Continuous Improvement|Despite some skepticism, there are no diminishing returns on scaling up AI models. Each new generation of AI models brings improvements in cost, efficiency, and capability.|
|Architectural Flexibility|It is crucial to maintain architectural flexibility to incorporate advancements in AI. This prevents being locked into solutions that become obsolete with the next major AI breakthrough.|
|Long-term Optimism and Societal Impact||
|Addressing Zero-Sum Problems|AI has the potential to turn zero-sum societal problems into non-zero-sum situations by creating technological breakthroughs that generate abundance.|
|Real-world Applications|AI can significantly improve sectors like healthcare and education. For instance, AI could assist overburdened healthcare systems by providing accurate diagnostics and treatment recommendations, thereby reducing unnecessary suffering.|
|Conclusion|While acknowledging the resource and data challenges in developing frontier models, it remains optimistic about AI's potential to solve critical societal issues and improve various domains of human life. The emphasis on flexibility, quality data, and assistive technology suggests a strategic approach to integrating AI into practical applications.|
